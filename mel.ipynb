{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:14:22 WARN Utils: Your hostname, Mels-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.99.64 instead (on interface en0)\n",
      "25/04/14 14:14:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/14 14:14:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 53787)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/socketserver.py\", line 318, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/socketserver.py\", line 349, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/socketserver.py\", line 362, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/socketserver.py\", line 761, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ExcelToSpark1\").getOrCreate()\n",
    "file1_pd = pd.read_csv(\"fl1.csv\")\n",
    "file2_pd = pd.read_csv(\"fl2.csv\")\n",
    "\n",
    "file1_spark = spark.createDataFrame(file1_pd)\n",
    "file2_spark = spark.createDataFrame(file2_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KEY: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- TITLE_COMPL: double (nullable = true)\n",
      " |-- PROSP3_MEASURE: string (nullable = true)\n",
      " |-- FREQ: string (nullable = true)\n",
      " |-- S_NCA: string (nullable = true)\n",
      " |-- PROSP3_SECURITIES_TYPE: string (nullable = true)\n",
      " |-- MTR: string (nullable = true)\n",
      " |-- CURR_ISSNC: string (nullable = true)\n",
      " |-- PROSP3_OFFER_TYPE: string (nullable = true)\n",
      " |-- PROSP3_DOCUMENT_TYPE: string (nullable = true)\n",
      " |-- SEC_TYPE_CFI: string (nullable = true)\n",
      " |-- ISSUER_COU: string (nullable = true)\n",
      " |-- ISSUER_SECTOR: string (nullable = true)\n",
      " |-- PROSP3_PRSP_TYPE: string (nullable = true)\n",
      " |-- PROSP3_SME_CAT_TYPE: string (nullable = true)\n",
      " |-- PROSP3_PSSP: string (nullable = true)\n",
      " |-- PROSP3_VENUE: string (nullable = true)\n",
      " |-- PROSP3_LNGG: string (nullable = true)\n",
      " |-- MV: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- GROUP: string (nullable = true)\n",
      " |-- TIME_PERIOD: string (nullable = true)\n",
      " |-- PK: double (nullable = true)\n",
      " |-- KEY: string (nullable = true)\n",
      " |-- OBS_VALUE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file1_spark.printSchema()\n",
    "file2_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KEY: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- TITLE_COMPL: double (nullable = true)\n",
      " |-- PROSP3_MEASURE: string (nullable = true)\n",
      " |-- FREQ: string (nullable = true)\n",
      " |-- S_NCA: string (nullable = true)\n",
      " |-- PROSP3_SECURITIES_TYPE: string (nullable = true)\n",
      " |-- MTR: string (nullable = true)\n",
      " |-- CURR_ISSNC: string (nullable = true)\n",
      " |-- PROSP3_OFFER_TYPE: string (nullable = true)\n",
      " |-- PROSP3_DOCUMENT_TYPE: string (nullable = true)\n",
      " |-- SEC_TYPE_CFI: string (nullable = true)\n",
      " |-- ISSUER_COU: string (nullable = true)\n",
      " |-- ISSUER_SECTOR: string (nullable = true)\n",
      " |-- PROSP3_PRSP_TYPE: string (nullable = true)\n",
      " |-- PROSP3_SME_CAT_TYPE: string (nullable = true)\n",
      " |-- PROSP3_PSSP: string (nullable = true)\n",
      " |-- PROSP3_VENUE: string (nullable = true)\n",
      " |-- PROSP3_LNGG: string (nullable = true)\n",
      " |-- MV: string (nullable = true)\n",
      " |-- GROUP: string (nullable = true)\n",
      " |-- TIME_PERIOD: string (nullable = true)\n",
      " |-- PK: double (nullable = true)\n",
      " |-- OBS_VALUE: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:16:46 WARN TaskSetManager: Stage 1 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11|1.10091597E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11|1.04203232E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|1.62175002E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q2| 2.6629E11|1.38165594E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2025-Q1| 3.8655E11| 9.5746394E8|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q2|5.58349E11|1.75963392E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q2|6.87196E11|1.10206182E9|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = file1_spark.join(file2_spark, on='KEY', how='left')\n",
    "df_joined.printSchema()\n",
    "df_joined.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be converting this into a pandas dataframe just for simpler data exploration, to see the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:16:48 WARN TaskSetManager: Stage 6 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "pd_df = df_joined.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>TITLE_COMPL</th>\n",
       "      <th>PROSP3_MEASURE</th>\n",
       "      <th>FREQ</th>\n",
       "      <th>S_NCA</th>\n",
       "      <th>PROSP3_SECURITIES_TYPE</th>\n",
       "      <th>MTR</th>\n",
       "      <th>CURR_ISSNC</th>\n",
       "      <th>PROSP3_OFFER_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>PROSP3_PRSP_TYPE</th>\n",
       "      <th>PROSP3_SME_CAT_TYPE</th>\n",
       "      <th>PROSP3_PSSP</th>\n",
       "      <th>PROSP3_VENUE</th>\n",
       "      <th>PROSP3_LNGG</th>\n",
       "      <th>MV</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>PK</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>6.786070e+11</td>\n",
       "      <td>9.768010e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>8.246360e+11</td>\n",
       "      <td>4.969537e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>2.662900e+11</td>\n",
       "      <td>2.070886e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q4</td>\n",
       "      <td>4.294990e+11</td>\n",
       "      <td>2.208926e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2024-Q4</td>\n",
       "      <td>8.160470e+11</td>\n",
       "      <td>2.500000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed CIIs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2023-Q4</td>\n",
       "      <td>2.748810e+11</td>\n",
       "      <td>4.341785e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.CF.Z.ZALL.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed FoFs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Y.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>1.460310e+11</td>\n",
       "      <td>2.070886e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>7.387360e+11</td>\n",
       "      <td>2.483136e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2023-Q4</td>\n",
       "      <td>2.748810e+11</td>\n",
       "      <td>1.601566e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2024-Q3</td>\n",
       "      <td>7.645060e+11</td>\n",
       "      <td>2.860072e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q4</td>\n",
       "      <td>8.246360e+11</td>\n",
       "      <td>1.100916e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q1</td>\n",
       "      <td>2.662900e+11</td>\n",
       "      <td>1.042032e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q4</td>\n",
       "      <td>4.294990e+11</td>\n",
       "      <td>1.621750e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q2</td>\n",
       "      <td>2.662900e+11</td>\n",
       "      <td>1.381656e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>3.865500e+11</td>\n",
       "      <td>9.574639e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2022-Q2</td>\n",
       "      <td>5.583490e+11</td>\n",
       "      <td>1.759634e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2023-Q2</td>\n",
       "      <td>6.871960e+11</td>\n",
       "      <td>1.102062e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2024-Q4</td>\n",
       "      <td>8.160470e+11</td>\n",
       "      <td>5.558434e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2021-Q3</td>\n",
       "      <td>6.786070e+11</td>\n",
       "      <td>6.222589e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>Quarterly consideration offered of filed Debt ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[MV] Consideration offer in EUR</td>\n",
       "      <td>[Q] quarterly</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2023-Q1</td>\n",
       "      <td>7.731221e+10</td>\n",
       "      <td>5.563471e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               KEY  \\\n",
       "0       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "1       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "2       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "3       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "4       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "5       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.C.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "6   PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.CF.Z.ZALL.Z.Z.Z.Z.Z.Z   \n",
       "7       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "8       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "9       PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "10      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "11      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "12      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "13      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "14      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "15      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "16      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "17      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "18      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "19      PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.D.Z.Z.Z.Z.Z.Z.Z.Z   \n",
       "\n",
       "                                                TITLE  TITLE_COMPL  \\\n",
       "0   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "1   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "2   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "3   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "4   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "5   Quarterly consideration offered of filed CIIs ...          NaN   \n",
       "6   Quarterly consideration offered of filed FoFs ...          NaN   \n",
       "7   Quarterly consideration offered of filed Debt ...          NaN   \n",
       "8   Quarterly consideration offered of filed Debt ...          NaN   \n",
       "9   Quarterly consideration offered of filed Debt ...          NaN   \n",
       "10  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "11  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "12  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "13  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "14  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "15  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "16  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "17  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "18  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "19  Quarterly consideration offered of filed Debt ...          NaN   \n",
       "\n",
       "                     PROSP3_MEASURE           FREQ      S_NCA  \\\n",
       "0   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "1   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "2   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "3   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "4   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "5   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "6   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "7   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "8   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "9   [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "10  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "11  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "12  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "13  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "14  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "15  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "16  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "17  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "18  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "19  [MV] Consideration offer in EUR  [Q] quarterly  [A0] EEA3   \n",
       "\n",
       "   PROSP3_SECURITIES_TYPE MTR CURR_ISSNC PROSP3_OFFER_TYPE  ...  \\\n",
       "0                       Z   Z          Z                 Z  ...   \n",
       "1                       Z   Z          Z                 Z  ...   \n",
       "2                       Z   Z          Z                 Z  ...   \n",
       "3                       Z   Z          Z                 Z  ...   \n",
       "4                       Z   Z          Z                 Z  ...   \n",
       "5                       Z   Z          Z                 Z  ...   \n",
       "6                       Z   Z          Z                 Z  ...   \n",
       "7                       Z   Z          Z                 Z  ...   \n",
       "8                       Z   Z          Z                 Z  ...   \n",
       "9                       Z   Z          Z                 Z  ...   \n",
       "10                      Z   Z          Z                 Z  ...   \n",
       "11                      Z   Z          Z                 Z  ...   \n",
       "12                      Z   Z          Z                 Z  ...   \n",
       "13                      Z   Z          Z                 Z  ...   \n",
       "14                      Z   Z          Z                 Z  ...   \n",
       "15                      Z   Z          Z                 Z  ...   \n",
       "16                      Z   Z          Z                 Z  ...   \n",
       "17                      Z   Z          Z                 Z  ...   \n",
       "18                      Z   Z          Z                 Z  ...   \n",
       "19                      Z   Z          Z                 Z  ...   \n",
       "\n",
       "   PROSP3_PRSP_TYPE PROSP3_SME_CAT_TYPE PROSP3_PSSP PROSP3_VENUE PROSP3_LNGG  \\\n",
       "0                 Z                   Z           Z            Z           Z   \n",
       "1                 Z                   Z           Z            Z           Z   \n",
       "2                 Z                   Z           Z            Z           Z   \n",
       "3                 Z                   Z           Z            Z           Z   \n",
       "4                 Z                   Z           Z            Z           Z   \n",
       "5                 Z                   Z           Z            Z           Z   \n",
       "6                 Z                   Z           Z            Z           Z   \n",
       "7                 Z                   Z           Z            Z           Z   \n",
       "8                 Z                   Z           Z            Z           Z   \n",
       "9                 Z                   Z           Z            Z           Z   \n",
       "10                Z                   Z           Z            Z           Z   \n",
       "11                Z                   Z           Z            Z           Z   \n",
       "12                Z                   Z           Z            Z           Z   \n",
       "13                Z                   Z           Z            Z           Z   \n",
       "14                Z                   Z           Z            Z           Z   \n",
       "15                Z                   Z           Z            Z           Z   \n",
       "16                Z                   Z           Z            Z           Z   \n",
       "17                Z                   Z           Z            Z           Z   \n",
       "18                Z                   Z           Z            Z           Z   \n",
       "19                Z                   Z           Z            Z           Z   \n",
       "\n",
       "   MV                                      GROUP TIME_PERIOD            PK  \\\n",
       "0   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q3  6.786070e+11   \n",
       "1   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q4  8.246360e+11   \n",
       "2   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2022-Q1  2.662900e+11   \n",
       "3   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2022-Q4  4.294990e+11   \n",
       "4   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2024-Q4  8.160470e+11   \n",
       "5   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q4  2.748810e+11   \n",
       "6   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Y.Z.Z.Z.Z.Z.Z     2022-Q1  1.460310e+11   \n",
       "7   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q1  7.387360e+11   \n",
       "8   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q4  2.748810e+11   \n",
       "9   Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2024-Q3  7.645060e+11   \n",
       "10  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q4  8.246360e+11   \n",
       "11  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2022-Q1  2.662900e+11   \n",
       "12  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2022-Q4  4.294990e+11   \n",
       "13  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q2  2.662900e+11   \n",
       "14  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2025-Q1  3.865500e+11   \n",
       "15  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2022-Q2  5.583490e+11   \n",
       "16  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q2  6.871960e+11   \n",
       "17  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2024-Q4  8.160470e+11   \n",
       "18  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2021-Q3  6.786070e+11   \n",
       "19  Z  PROSP3.MV.Q.Y.Z.Z.Z.Z.Z.Y.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q1  7.731221e+10   \n",
       "\n",
       "       OBS_VALUE  \n",
       "0   9.768010e+06  \n",
       "1   4.969537e+07  \n",
       "2   2.070886e+07  \n",
       "3   2.208926e+07  \n",
       "4   2.500000e+07  \n",
       "5   4.341785e+07  \n",
       "6   2.070886e+07  \n",
       "7   2.483136e+08  \n",
       "8   1.601566e+09  \n",
       "9   2.860072e+09  \n",
       "10  1.100916e+09  \n",
       "11  1.042032e+09  \n",
       "12  1.621750e+09  \n",
       "13  1.381656e+09  \n",
       "14  9.574639e+08  \n",
       "15  1.759634e+09  \n",
       "16  1.102062e+09  \n",
       "17  5.558434e+09  \n",
       "18  6.222589e+08  \n",
       "19  5.563471e+08  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay here the title_compl column is filled with NaNs meaning that there was probably a Null entry that overrid the whole column. fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outlier_thresholds(\n",
    "    data,\n",
    "    numbercol,\n",
    "    groupbycols=None,\n",
    "    showstats=False,\n",
    "    use_logs=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Identifies outliers in the specified column based on whether they exceed the\n",
    "    median by over 3 or 4 standard deviations.\n",
    "    \"\"\"\n",
    "    if groupbycols is None:\n",
    "        groupbycols = []\n",
    "\n",
    "    col3sd = numbercol + '_3sd'\n",
    "    col4sd = numbercol + '_4sd'\n",
    "\n",
    "    stats = (data\n",
    "             .groupBy(groupbycols)\n",
    "             .agg(\n",
    "                 f.expr(f'percentile_approx({numbercol}, 0.5)').alias('median'),\n",
    "                 f.stddev(f.col(numbercol)).alias('stddev')\n",
    "             )\n",
    "             .withColumn('3sd', f.col('median') + f.col('stddev')*3)\n",
    "             .withColumn('4sd', f.col('median') + f.col('stddev')*4)\n",
    "    )\n",
    "\n",
    "    if groupbycols:\n",
    "        data_alias = data.alias('data')\n",
    "        stats_alias = stats.alias('stats')\n",
    "\n",
    "        join_expr = reduce(\n",
    "            lambda x, y: x & y,\n",
    "            [f.col('data.' + c).eqNullSafe(f.col('stats.' + c))\n",
    "             for c in groupbycols]\n",
    "        )\n",
    "        data = (data_alias\n",
    "                .join(stats_alias, on=join_expr, how='left')\n",
    "                .drop(*[f.col('stats.' + c) for c in groupbycols])\n",
    "        )\n",
    "    else:\n",
    "        data = (data\n",
    "                .withColumn('dummykey', f.lit(1))\n",
    "                .join(\n",
    "                    stats.withColumn('dummykey', f.lit(1)),\n",
    "                    on='dummykey',\n",
    "                    how='left'\n",
    "                )\n",
    "                .drop('dummykey')\n",
    "        )\n",
    "\n",
    "    if use_logs:\n",
    "        data = (data\n",
    "                .withColumn(\n",
    "                    col3sd,\n",
    "                    f.when(f.log(f.abs(f.col(numbercol))) > f.col('3sd'), True)\n",
    "                     .otherwise(False)\n",
    "                )\n",
    "                .withColumn(\n",
    "                    col4sd,\n",
    "                    f.when(f.log(f.abs(f.col(numbercol))) > f.col('4sd'), True)\n",
    "                     .otherwise(False)\n",
    "                )\n",
    "                .drop('median', 'stddev', '3sd', '4sd')\n",
    "        )\n",
    "    else:\n",
    "        data = (data\n",
    "                .withColumn(\n",
    "                    col3sd,\n",
    "                    f.when(f.col(numbercol) > f.col('3sd'), True).otherwise(False)\n",
    "                )\n",
    "                .withColumn(\n",
    "                    col4sd,\n",
    "                    f.when(f.col(numbercol) > f.col('4sd'), True).otherwise(False)\n",
    "                )\n",
    "                .drop('median', 'stddev', '3sd', '4sd')\n",
    "        )\n",
    "\n",
    "    if showstats:\n",
    "        count_3sd = data.filter(f.col(col3sd) == True).count()\n",
    "        count_4sd = data.filter(f.col(col4sd) == True).count()\n",
    "        print(f\"Number of >3sd outliers in {numbercol}: {count_3sd}\")\n",
    "        print(f\"Number of >4sd outliers in {numbercol}: {count_4sd}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def melisa_outliers(\n",
    "    spark_df,\n",
    "    mode='thresholds',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=None,\n",
    "    showstats=False,\n",
    "    use_logs=False,\n",
    "    min_filter=None,\n",
    "    min_date=None,\n",
    "    feature_cols=None\n",
    "):\n",
    "\n",
    "    if groupbycols is None:\n",
    "        groupbycols = []\n",
    "\n",
    "    if mode == 'random_forest_regressor':\n",
    "\n",
    "        df_pd = spark_df.toPandas()\n",
    "\n",
    "        if feature_cols is None:\n",
    "            numeric_cols = df_pd.select_dtypes(include=[float, int]).columns\n",
    "            feature_cols = [c for c in numeric_cols if c != numbercol]\n",
    "\n",
    "        # Drop any rows missing target or features\n",
    "        df_pd = df_pd.dropna(subset=[numbercol] + feature_cols)\n",
    "\n",
    "        X = df_pd[feature_cols]\n",
    "        y = df_pd[numbercol]\n",
    "\n",
    "        rfr = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        rfr.fit(X, y)\n",
    "\n",
    "        #pred residuals\n",
    "\n",
    "        df_pd['pred_rfr'] = rfr.predict(X)\n",
    "        df_pd['residual_rfr'] = df_pd[numbercol] - df_pd['pred_rfr']\n",
    "        resid_std = df_pd['residual_rfr'].std()\n",
    "        threshold_3sd = 3 * resid_std\n",
    "\n",
    "        df_pd['rfr_outlier'] = (df_pd['residual_rfr'].abs() > threshold_3sd)\n",
    "\n",
    "        # opt do for 4 as well\n",
    "        # df_pd['rfr_outlier_4sd'] = (df_pd['residual_rfr'].abs() > threshold_4sd)\n",
    "\n",
    "        if showstats:\n",
    "            print(\"Random Forest Regressor-based Outliers:\")\n",
    "            print(df_pd['rfr_outlier'].value_counts())\n",
    "\n",
    "        new_df = spark.createDataFrame(df_pd)\n",
    "        return new_df\n",
    "\n",
    "    elif mode == 'thresholds':\n",
    "        if min_filter is not None:\n",
    "            spark_df = spark_df.filter(f.col(numbercol) > min_filter)\n",
    "\n",
    "        out_df = add_outlier_thresholds(\n",
    "            data=spark_df,\n",
    "            numbercol=numbercol,\n",
    "            groupbycols=groupbycols,\n",
    "            showstats=showstats,\n",
    "            use_logs=use_logs\n",
    "        )\n",
    "        return out_df\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:16:52 WARN TaskSetManager: Stage 11 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/14 14:16:54 WARN TaskSetManager: Stage 30 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of >3sd outliers in OBS_VALUE: 1785\n",
      "Number of >4sd outliers in OBS_VALUE: 1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:16:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/04/14 14:16:55 WARN TaskSetManager: Stage 49 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/14 14:16:55 WARN TaskSetManager: Stage 51 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 51:====================================>                    (7 + 4) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+----------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+---------------+------------+-------------+-------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|   ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|             PK|   OBS_VALUE|OBS_VALUE_3sd|OBS_VALUE_4sd|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+----------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+---------------+------------+-------------+-------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|     7.64506E11|2.86007219E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|  [DB] Bonds|         Z|[S13] Government|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|      4.5527E11| 3.0274508E7|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q3|     4.98219E11|3.98252595E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q2|      2.6629E11|1.38165594E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|     2.74881E11|1.60156595E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|  [DB] Bonds|         Z|[S13] Government|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|      3.1783E11|  2.922938E7|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q2|     5.58349E11|1.75963392E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q1|7.7312212641E10| 5.5634707E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|  [DB] Bonds|         Z|[S13] Government|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q1|     1.37441E11| 3.5157416E7|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|     4.29499E11|1.62175002E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q2|     2.06161E11|1.82112371E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|  [DB] Bonds|         Z|[S13] Government|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q2|     6.52837E11|1.29623472E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|     7.38736E11|2.48313584E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|     8.24636E11|1.10091597E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q3|      2.6629E11| 9.4678912E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q3|     6.78607E11| 6.2225894E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2025-Q1|      3.8655E11| 9.5746394E8|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1|      2.6629E11|1.04203232E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q2|     6.87196E11|1.10206182E9|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|               Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q4|     8.16047E11| 5.5584343E9|        false|        false|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+----------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+---------------+------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# If you only need the data from file2_spark:\n",
    "df_out = melisa_outliers(\n",
    "    spark_df=df_joined,\n",
    "    mode='thresholds',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=['TIME_PERIOD'],  # group by TIME_PERIOD\n",
    "    showstats=True,\n",
    "    use_logs=False\n",
    ")\n",
    "\n",
    "df_out.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    " bcs of the null issue i just deleted it( ill fix later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:16:56 WARN TaskSetManager: Stage 67 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor-based Outliers:\n",
      "rfr_outlier\n",
      "False    150825\n",
      "True       1203\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_notitle = df_joined.drop('TITLE_COMPL')\n",
    "\n",
    "df_out2 = melisa_outliers(\n",
    "    spark_df=df_notitle,\n",
    "    mode='random_forest_regressor',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=['TIME_PERIOD'],\n",
    "    showstats=True,\n",
    "    use_logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:06 WARN TaskSetManager: Stage 71 contains a task of very large size (4860 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf_out = df_out2.toPandas()\n",
    "#pdf_outliers = pdf_out[pdf_out['OBS_VALUE_4sd'] == True]\n",
    "pdf_outliers = pdf_out[pdf_out['rfr_outlier'] == True]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(\n",
    "    pdf_out.index,\n",
    "    pdf_out['OBS_VALUE'],\n",
    "    marker='o',\n",
    "    linestyle='',\n",
    "    color='blue',\n",
    "    alpha=0.5,\n",
    "    label='All data'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    pdf_outliers.index,\n",
    "    pdf_outliers['OBS_VALUE'],\n",
    "    color='red',\n",
    "    label='Outliers'\n",
    ")\n",
    "\n",
    "plt.xlabel('Index (row order)')\n",
    "plt.ylabel('OBS_VALUE')\n",
    "plt.title('Time Series of OBS_VALUE with Outliers Flagged')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is by index so doesnt make too much sense, to make it in a more time series way, we parse the quarters as specific months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quarters(date_str):\n",
    "    \"\"\"\n",
    "    Parses a date string in the format 'YYYY-QX' and returns the corresponding\n",
    "    datetime object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        year_str, q_str2 = date_str.split('-Q')\n",
    "        year = int(year_str)\n",
    "        quarter = int(q_str2)\n",
    "        month = (quarter - 1)*3 + 1\n",
    "\n",
    "        return pd.Timestamp(year=year, month=month, day=1)\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:18 WARN TaskSetManager: Stage 72 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 72:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|     ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|       quarter_date|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q3|6.78607E11|   9768010.0|2021-07-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11| 4.9695368E7|2021-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11| 2.0708856E7|2022-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|  2.208926E7|2022-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q4|8.16047E11|       2.5E7|2024-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11| 4.3417852E7|2023-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|   [CF] FoFs|         Z|[ZALL] All sectors|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1|1.46031E11| 2.0708856E7|2022-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|2021-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|2023-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|2024-07-01 00:00:00|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:22 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 72 (TID 216): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pd_df['quarter_date'] = pd_df['TIME_PERIOD'].apply(parse_quarters)\n",
    "the_df = spark.createDataFrame(pd_df)\n",
    "the_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:22 WARN TaskSetManager: Stage 73 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+-------------+-------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|     ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|       quarter_date|OBS_VALUE_3sd|OBS_VALUE_4sd|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+-------------+-------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q3|6.78607E11|   9768010.0|2021-07-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11| 4.9695368E7|2021-10-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11| 2.0708856E7|2022-01-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|  2.208926E7|2022-10-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q4|8.16047E11|       2.5E7|2024-10-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11| 4.3417852E7|2023-10-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|   [CF] FoFs|         Z|[ZALL] All sectors|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1|1.46031E11| 2.0708856E7|2022-01-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|2021-01-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|2023-10-01 00:00:00|        false|        false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|2024-07-01 00:00:00|        false|        false|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:23 WARN TaskSetManager: Stage 76 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "df_c = the_df\n",
    "\n",
    "a = melisa_outliers(df_c)\n",
    "a.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:23 WARN TaskSetManager: Stage 77 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/14 14:17:23 WARN TaskSetManager: Stage 80 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor-based Outliers:\n",
      "rfr_outlier\n",
      "False    150825\n",
      "True       1203\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = a.drop('TITLE_COMPL')\n",
    "\n",
    "b = melisa_outliers(\n",
    "    spark_df=a,\n",
    "    mode='random_forest_regressor',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=['TIME_PERIOD'],\n",
    "    showstats=True,\n",
    "    use_logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/14 14:17:38 WARN TaskSetManager: Stage 81 contains a task of very large size (5003 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 02:27:05 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1023912 ms exceeds timeout 120000 ms\n",
      "25/04/15 02:27:05 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/04/15 02:39:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 02:39:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 02:56:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 02:56:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:06:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:06:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:22:20 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:22:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:22:30 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:22:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:57:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 03:57:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 04:11:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 04:11:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 04:28:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 04:28:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 05:01:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 05:01:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 05:34:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 05:34:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 06:03:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 06:03:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 06:20:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 06:20:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 06:51:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 06:51:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:06:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:06:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:07:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:07:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:08:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:09:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:09:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:26:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:26:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:27:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:27:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:28:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:28:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:28:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:28:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:29:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:29:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:29:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:29:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:30:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:30:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:46:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:46:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:46:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:46:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:47:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:47:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:48:18 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:48:18 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:48:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:48:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 07:49:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 07:49:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 08:05:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:05:08 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:05:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:05:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:06:43 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:06:43 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:06:53 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:06:53 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:07:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:07:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:08:03 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:08:03 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:08:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:08:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:22:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 08:23:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 08:23:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:23:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:24:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 08:25:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/15 08:25:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.99.64:53759\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/15 08:25:57 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf_out = b.toPandas()\n",
    "#pdf_outliers = pdf_out[pdf_out['OBS_VALUE_4sd'] == True]\n",
    "pdf_outliers = pdf_out[pdf_out['rfr_outlier'] == True]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(\n",
    "    pdf_out['quarter_date'],\n",
    "    pdf_out['OBS_VALUE'],\n",
    "    marker='o',\n",
    "    linestyle='',\n",
    "    color='blue',\n",
    "    alpha=0.1,\n",
    "    label='All data'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    pdf_outliers['quarter_date'],\n",
    "    pdf_outliers['OBS_VALUE'],\n",
    "    color='red',\n",
    "    label='Outliers'\n",
    ")\n",
    "\n",
    "plt.xlabel('Quarter date')\n",
    "plt.ylabel('OBS_VALUE')\n",
    "plt.title('Time Series of OBS_VALUE with Outliers Flagged')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### too many outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
