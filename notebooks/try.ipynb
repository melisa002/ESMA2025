{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- KEY: string (nullable = true)\n",
      " |-- TITLE: string (nullable = true)\n",
      " |-- TITLE_COMPL: double (nullable = true)\n",
      " |-- PROSP3_MEASURE: string (nullable = true)\n",
      " |-- FREQ: string (nullable = true)\n",
      " |-- S_NCA: string (nullable = true)\n",
      " |-- PROSP3_SECURITIES_TYPE: string (nullable = true)\n",
      " |-- MTR: string (nullable = true)\n",
      " |-- CURR_ISSNC: string (nullable = true)\n",
      " |-- PROSP3_OFFER_TYPE: string (nullable = true)\n",
      " |-- PROSP3_DOCUMENT_TYPE: string (nullable = true)\n",
      " |-- SEC_TYPE_CFI: string (nullable = true)\n",
      " |-- ISSUER_COU: string (nullable = true)\n",
      " |-- ISSUER_SECTOR: string (nullable = true)\n",
      " |-- PROSP3_PRSP_TYPE: string (nullable = true)\n",
      " |-- PROSP3_SME_CAT_TYPE: string (nullable = true)\n",
      " |-- PROSP3_PSSP: string (nullable = true)\n",
      " |-- PROSP3_VENUE: string (nullable = true)\n",
      " |-- PROSP3_LNGG: string (nullable = true)\n",
      " |-- MV: string (nullable = true)\n",
      " |-- GROUP: string (nullable = true)\n",
      " |-- TIME_PERIOD: string (nullable = true)\n",
      " |-- PK: double (nullable = true)\n",
      " |-- OBS_VALUE: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:06 WARN TaskSetManager: Stage 22 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11|1.10091597E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11|1.04203232E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|1.62175002E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q2| 2.6629E11|1.38165594E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2025-Q1| 3.8655E11| 9.5746394E8|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q2|5.58349E11|1.75963392E9|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|            Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q2|6.87196E11|1.10206182E9|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+-------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark.sql.functions as f\n",
    "from functools import reduce\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ExcelToSpark1\").getOrCreate()\n",
    "file1_pd = pd.read_csv(\"fl1.csv\")\n",
    "file2_pd = pd.read_csv(\"fl2.csv\")\n",
    "\n",
    "file1_spark = spark.createDataFrame(file1_pd)\n",
    "file2_spark = spark.createDataFrame(file2_pd)\n",
    "\n",
    "df_joined = file1_spark.join(file2_spark, on='KEY', how='left')\n",
    "df_joined.printSchema()\n",
    "df_joined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quarters(date_str):\n",
    "    \"\"\"\n",
    "    Parses a date string in the format 'YYYY-QX' and returns the corresponding\n",
    "    datetime object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        year_str, q_str2 = date_str.split('-Q')\n",
    "        year = int(year_str)\n",
    "        quarter = int(q_str2)\n",
    "        month = (quarter - 1)*3 + 1\n",
    "\n",
    "        return pd.Timestamp(year=year, month=month, day=1)\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:07 WARN TaskSetManager: Stage 27 contains a task of very large size (1029 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/04/21 17:33:17 WARN TaskSetManager: Stage 31 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "[Stage 31:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|     ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|       quarter_date|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q3|6.78607E11|   9768010.0|2021-07-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11| 4.9695368E7|2021-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11| 2.0708856E7|2022-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|  2.208926E7|2022-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q4|8.16047E11|       2.5E7|2024-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11| 4.3417852E7|2023-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|   [CF] FoFs|         Z|[ZALL] All sectors|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1|1.46031E11| 2.0708856E7|2022-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|2021-01-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|2023-10-01 00:00:00|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|2024-07-01 00:00:00|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:21 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 31 (TID 191): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_joined = df_joined.toPandas()\n",
    "df_joined['quarter_date'] = df_joined['TIME_PERIOD'].apply(parse_quarters)\n",
    "df_joined = spark.createDataFrame(df_joined)\n",
    "df_joined.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_outlier_thresholds(\n",
    "    data,\n",
    "    numbercol,\n",
    "    groupbycols=None,\n",
    "    showstats=False,\n",
    "    use_logs=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Flags outliers in the specified numeric column based on being above\n",
    "    the group-level median + 3 or 4 standard deviations.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Spark DataFrame\n",
    "    - numbercol: str, column to evaluate\n",
    "    - groupbycols: list of str, columns to group by\n",
    "    - showstats: bool, print number of outliers\n",
    "    - use_logs: bool, apply log to the column before comparison\n",
    "    \"\"\"\n",
    "    if groupbycols is None:\n",
    "        groupbycols = []\n",
    "\n",
    "    col3sd = f\"{numbercol}_3sd\"\n",
    "    col4sd = f\"{numbercol}_4sd\"\n",
    "\n",
    "    # Compute median and stddev per group\n",
    "    stats_df = (\n",
    "        data.groupBy(groupbycols)\n",
    "        .agg(\n",
    "            f.expr(f'percentile_approx({numbercol}, 0.5)').alias('median'),\n",
    "            f.stddev(numbercol).alias('stddev')\n",
    "        )\n",
    "        .withColumn('threshold_3sd', f.col('median') + 3 * f.col('stddev'))\n",
    "        .withColumn('threshold_4sd', f.col('median') + 4 * f.col('stddev'))\n",
    "    )\n",
    "\n",
    "    # Join stats back to data\n",
    "    if groupbycols:\n",
    "        join_condition = reduce(\n",
    "            lambda x, y: x & y,\n",
    "            [f.col(f\"data.{col}\") == f.col(f\"stats.{col}\") for col in groupbycols]\n",
    "        )\n",
    "\n",
    "        data = (\n",
    "            data.alias(\"data\")\n",
    "            .join(stats_df.alias(\"stats\"), on=join_condition, how=\"left\")\n",
    "        )\n",
    "    else:\n",
    "        data = (\n",
    "            data.withColumn('dummykey', f.lit(1))\n",
    "            .join(stats_df.withColumn('dummykey', f.lit(1)), on='dummykey', how='left')\n",
    "            .drop('dummykey')\n",
    "        )\n",
    "\n",
    "    # Flag outliers\n",
    "    if use_logs:\n",
    "        data = data.withColumn(\n",
    "            col3sd, f.when(f.log(f.abs(f.col(numbercol))) > f.col('threshold_3sd'), True).otherwise(False)\n",
    "        ).withColumn(\n",
    "            col4sd, f.when(f.log(f.abs(f.col(numbercol))) > f.col('threshold_4sd'), True).otherwise(False)\n",
    "        )\n",
    "    else:\n",
    "        data = data.withColumn(\n",
    "            col3sd, f.when(f.col(numbercol) > f.col('threshold_3sd'), True).otherwise(False)\n",
    "        ).withColumn(\n",
    "            col4sd, f.when(f.col(numbercol) > f.col('threshold_4sd'), True).otherwise(False)\n",
    "        )\n",
    "\n",
    "    # Show stats\n",
    "    if showstats:\n",
    "        count_3sd = data.filter(f.col(col3sd)).count()\n",
    "        count_4sd = data.filter(f.col(col4sd)).count()\n",
    "        print(f\"[3SD OUTLIERS] {numbercol}: {count_3sd}\")\n",
    "        print(f\"[4SD OUTLIERS] {numbercol}: {count_4sd}\")\n",
    "\n",
    "    return data.drop('median', 'stddev', 'threshold_3sd', 'threshold_4sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as f  # make sure you have this import\n",
    "\n",
    "def melisa_outliers(\n",
    "    spark_df,\n",
    "    mode='thresholds',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=None,\n",
    "    showstats=False,\n",
    "    use_logs=False,\n",
    "    min_filter=None,\n",
    "    min_date=None,          # e.g. '2023-01-01'\n",
    "    feature_cols=None\n",
    "):\n",
    "    if groupbycols is None:\n",
    "        groupbycols = []\n",
    "\n",
    "    # 1) Convert TIME_PERIOD -> real date for filtering\n",
    "    def parse_quarters(date_str):\n",
    "        try:\n",
    "            y, q = date_str.split('-Q')\n",
    "            m = (int(q)-1)*3 + 1\n",
    "            return pd.Timestamp(year=int(y), month=m, day=1)\n",
    "        except:\n",
    "            return pd.NaT\n",
    "\n",
    "    # Convert Spark -> pandas\n",
    "    df_pd = spark_df.toPandas()\n",
    "    df_pd['quarter_date'] = df_pd['TIME_PERIOD'].apply(parse_quarters)\n",
    "\n",
    "    # 2) Apply min_date and min_filter\n",
    "    if min_date is not None:\n",
    "        cutoff = pd.to_datetime(min_date)\n",
    "        df_pd = df_pd[df_pd['quarter_date'] >= cutoff]\n",
    "    if min_filter is not None:\n",
    "        df_pd = df_pd[df_pd[numbercol] >= min_filter]\n",
    "\n",
    "    if mode == 'random_forest_regressor':\n",
    "        # 3) Figure out features\n",
    "        if feature_cols is None:\n",
    "            numeric = df_pd.select_dtypes(include=['float','int']).columns.tolist()\n",
    "            feature_cols = [c for c in numeric if c != numbercol]\n",
    "\n",
    "        # Helper to train & flag per group\n",
    "        def process_group(grp):\n",
    "            if grp.shape[0] < 10:\n",
    "                grp['rfr_outlier'] = False\n",
    "                return grp\n",
    "\n",
    "            X = grp[feature_cols]\n",
    "            y = grp[numbercol]\n",
    "            model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            grp['pred_rfr']      = model.predict(X)\n",
    "            grp['residual_rfr']  = grp[numbercol] - grp['pred_rfr']\n",
    "            sd = grp['residual_rfr'].std()\n",
    "            thresh = 4 * sd\n",
    "\n",
    "            grp['rfr_outlier'] = grp['residual_rfr'].abs() > thresh\n",
    "            return grp\n",
    "\n",
    "        # 4) Apply per‐group (or once if no grouping)\n",
    "        if groupbycols:\n",
    "            df_out = (\n",
    "                df_pd\n",
    "                .groupby(groupbycols, group_keys=False)\n",
    "                .apply(process_group)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "        else:\n",
    "            df_out = process_group(df_pd)\n",
    "\n",
    "        if showstats:\n",
    "            print(df_out['rfr_outlier'].value_counts())\n",
    "\n",
    "        # 5) Anything under min_filter must be False\n",
    "        if min_filter is not None:\n",
    "            df_out.loc[df_out[numbercol] < min_filter, 'rfr_outlier'] = False\n",
    "\n",
    "        return spark.createDataFrame(df_out)\n",
    "\n",
    "    elif mode == 'thresholds':\n",
    "        # apply the existing threshold logic\n",
    "        df_thresh = spark_df\n",
    "        if min_filter is not None:\n",
    "            df_thresh = df_thresh.filter(f.col(numbercol) >= min_filter)\n",
    "        if min_date is not None:\n",
    "            # make sure quarter_date column exists as date\n",
    "            df_thresh = df_thresh.withColumn(\n",
    "                'quarter_date',\n",
    "                f.to_date(f.col('TIME_PERIOD').substr(1,4).cast('int').cast('string')  # crude: extract year; adjust if you have quarter_date as a column\n",
    "            )).filter(f.col('quarter_date') >= f.lit(min_date))\n",
    "\n",
    "        # run your threshold outlier function, which gives back only the key cols + value + flag\n",
    "        outliers_only = add_outlier_thresholds(\n",
    "            data=df_thresh,\n",
    "            numbercol=numbercol,\n",
    "            groupbycols=groupbycols,\n",
    "            showstats=showstats,\n",
    "            use_logs=use_logs\n",
    "        )\n",
    "\n",
    "        # now join back to the original spark_df on the grouping keys + TIME_PERIOD + numbercol\n",
    "        join_keys = groupbycols + ['TIME_PERIOD', numbercol]\n",
    "        full_with_flags = spark_df.join(\n",
    "            outliers_only.select(*join_keys, 'is_outlier'),\n",
    "            on=join_keys,\n",
    "            how='left'\n",
    "        ).withColumn(\n",
    "            'is_outlier',\n",
    "            f.coalesce(f.col('is_outlier'), f.lit(False))\n",
    "        )\n",
    "\n",
    "        return full_with_flags\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:21 WARN TaskSetManager: Stage 32 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "/var/folders/v1/v83gn92x7vv8phs46b_nj2gr0000gn/T/ipykernel_60303/3970429507.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(process_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr_outlier\n",
      "False    151420\n",
      "True        608\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = melisa_outliers(\n",
    "    spark_df=df_joined,\n",
    "    mode='random_forest_regressor',\n",
    "    numbercol='OBS_VALUE',\n",
    "    groupbycols=['PROSP3_SME_CAT_TYPE', 'SEC_TYPE_CFI'],\n",
    "    showstats=True,\n",
    "    use_logs=False,\n",
    "    min_filter=0,\n",
    "    min_date=None,\n",
    "    feature_cols=['OBS_VALUE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:39 WARN TaskSetManager: Stage 33 contains a task of very large size (5094 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pdf_out = a.toPandas()\n",
    "#pdf_outliers = pdf_out[pdf_out['OBS_VALUE_4sd'] == True]\n",
    "pdf_outliers = pdf_out[pdf_out['rfr_outlier'] == True]\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(\n",
    "    pdf_out['quarter_date'],\n",
    "    pdf_out['OBS_VALUE'],\n",
    "    marker='o',\n",
    "    linestyle='',\n",
    "    color='blue',\n",
    "    alpha=0.1,\n",
    "    label='All data'\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    pdf_outliers['quarter_date'],\n",
    "    pdf_outliers['OBS_VALUE'],\n",
    "    color='red',\n",
    "    label='Outliers'\n",
    ")\n",
    "\n",
    "plt.xlabel('quarter')\n",
    "plt.ylabel('OBS_VALUE')\n",
    "plt.title('Time Series of OBS_VALUE with Outliers Flagged')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+--------------+-------------------+-----------+\n",
      "|                 KEY|               TITLE|TITLE_COMPL|      PROSP3_MEASURE|         FREQ|    S_NCA|PROSP3_SECURITIES_TYPE|MTR|CURR_ISSNC|PROSP3_OFFER_TYPE|PROSP3_DOCUMENT_TYPE|SEC_TYPE_CFI|ISSUER_COU|     ISSUER_SECTOR|PROSP3_PRSP_TYPE|PROSP3_SME_CAT_TYPE|PROSP3_PSSP|PROSP3_VENUE|PROSP3_LNGG| MV|               GROUP|TIME_PERIOD|        PK|   OBS_VALUE|       quarter_date|      pred_rfr|       residual_rfr|rfr_outlier|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+--------------+-------------------+-----------+\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q3|6.78607E11|   9768010.0|2021-07-01 00:00:00|     9768010.0|                0.0|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q4|8.24636E11| 4.9695368E7|2021-10-01 00:00:00| 4.970755328E7|-12185.280000001192|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1| 2.6629E11| 2.0708856E7|2022-01-01 00:00:00|   2.0708856E7|                0.0|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q4|4.29499E11|  2.208926E7|2022-10-01 00:00:00| 2.206165192E7| 27608.079999998212|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q4|8.16047E11|       2.5E7|2024-10-01 00:00:00|         2.5E7|                0.0|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [C] CIIs|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11| 4.3417852E7|2023-10-01 00:00:00| 4.337968296E7| 38169.039999999106|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|   [CF] FoFs|         Z|[ZALL] All sectors|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2022-Q1|1.46031E11| 2.0708856E7|2022-01-01 00:00:00|   2.0708856E7|                0.0|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2021-Q1|7.38736E11|2.48313584E8|2021-01-01 00:00:00| 2.481497984E8| 163785.59999999404|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2023-Q4|2.74881E11|1.60156595E9|2023-10-01 00:00:00|1.5999238642E9| 1642085.7999999523|      false|\n",
      "|PROSP3.MV.Q.A0.Z....|Quarterly conside...|        NaN|[MV] Consideratio...|[Q] quarterly|[A0] EEA3|                     Z|  Z|         Z|                Z|                   Z|    [D] Debt|         Z|                 Z|               Z|                  Z|          Z|           Z|          Z|  Z|PROSP3.MV.Q.Y.Z.Z...|    2024-Q3|7.64506E11|2.86007219E9|2024-07-01 00:00:00|2.8575257384E9| 2546451.5999999046|      false|\n",
      "+--------------------+--------------------+-----------+--------------------+-------------+---------+----------------------+---+----------+-----------------+--------------------+------------+----------+------------------+----------------+-------------------+-----------+------------+-----------+---+--------------------+-----------+----------+------------+-------------------+--------------+-------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:48 WARN TaskSetManager: Stage 34 contains a task of very large size (5094 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "a.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:48 WARN TaskSetManager: Stage 35 contains a task of very large size (5094 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = a.toPandas()\n",
    "\n",
    "plt.scatter(a['quarter_date'], a['OBS_VALUE'], alpha=0.3, label='All data')\n",
    "out = a[a['rfr_outlier']]\n",
    "plt.scatter(out['quarter_date'], out['OBS_VALUE'], color='red', label='RFR outliers')\n",
    "plt.legend()\n",
    "plt.title('OBS_VALUE over time with RFR outliers flagged')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1) parse your quarter into a real date\n",
    "parse_q = F.expr(\"\"\"\n",
    "  to_date(\n",
    "    concat(\n",
    "      split(TIME_PERIOD, '-Q')[0],\n",
    "      '-',\n",
    "      (cast(split(TIME_PERIOD, '-Q')[1] as int)-1)*3+1,\n",
    "      '-01'\n",
    "    )\n",
    "  )\n",
    "\"\"\")\n",
    "\n",
    "df2 = df_joined \\\n",
    "  .withColumn('quarter_date', parse_q)\n",
    "\n",
    "# 2) define a window per country+CFI, ordered by date\n",
    "w = Window.partitionBy('S_NCA','SEC_TYPE_CFI') \\\n",
    "          .orderBy('quarter_date')\n",
    "\n",
    "# 3) add one‑quarter lag\n",
    "df2 = df2.withColumn('lag1_obs', F.lag('OBS_VALUE').over(w))\n",
    "\n",
    "# 4) add a numeric time feature\n",
    "df2 = df2.withColumn('time_index',\n",
    "    F.year('quarter_date')*10 + ((F.quarter('quarter_date')-1))\n",
    ")\n",
    "\n",
    "# drop the first row per group (where lag1_obs is null)\n",
    "df2 = df2.filter(F.col('lag1_obs').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:33:51 WARN TaskSetManager: Stage 36 contains a task of very large size (4847 KiB). The maximum recommended task size is 1000 KiB.\n",
      "/var/folders/v1/v83gn92x7vv8phs46b_nj2gr0000gn/T/ipykernel_60303/3970429507.py:72: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(process_group)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr_outlier\n",
      "False    149525\n",
      "True       1803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "e = melisa_outliers(\n",
    "    spark_df    = df2,\n",
    "    mode        = 'random_forest_regressor',\n",
    "    numbercol   = 'OBS_VALUE',\n",
    "    groupbycols = ['S_NCA','SEC_TYPE_CFI'],\n",
    "    showstats   = True,\n",
    "    min_filter  = 0,\n",
    "    feature_cols= ['lag1_obs','time_index']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:34:19 WARN TaskSetManager: Stage 39 contains a task of very large size (5301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf = e.select('quarter_date','OBS_VALUE','rfr_outlier').toPandas()\n",
    "\n",
    "plt.scatter(pdf['quarter_date'], pdf['OBS_VALUE'], alpha=0.3, label='All data')\n",
    "o = pdf[pdf['rfr_outlier']]\n",
    "plt.scatter(o['quarter_date'], o['OBS_VALUE'], label='RFR outliers')\n",
    "plt.legend(); plt.title('OBS_VALUE over time with RFR outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 17:35:11 WARN TaskSetManager: Stage 41 contains a task of very large size (5301 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Select only the columns you need\n",
    "pdf = (\n",
    "    e\n",
    "    .select('KEY','TIME_PERIOD', 'S_NCA', 'SEC_TYPE_CFI',\n",
    "            'OBS_VALUE','quarter_date', 'rfr_outlier')\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S_NCA\n",
       "[A6] EEA30             16682\n",
       "[A1] World             16682\n",
       "[V5] EU27              16176\n",
       "[I8] EA19              14422\n",
       "[LU] Luxembourg         8950\n",
       "[IE] Ireland            7992\n",
       "[K0] EU not in EA19     7283\n",
       "[DE] Germany            6021\n",
       "[SE] Sweden             5352\n",
       "[FR] France             4707\n",
       "[A0] EEA3               3989\n",
       "[NL] Netherlands        3956\n",
       "[AT] Austria            3924\n",
       "[IT] Italy              2800\n",
       "[NO] Norway             2600\n",
       "[ES] Spain              2392\n",
       "[BE] Belgium            2316\n",
       "[LI] Liechtenstein      2260\n",
       "[CZ] Czechia            2007\n",
       "[PL] Poland             1877\n",
       "[SK] Slovakia           1859\n",
       "[BG] Bulgaria           1747\n",
       "[DK] Denmark            1736\n",
       "[FI] Finland            1643\n",
       "[IS] Iceland            1495\n",
       "[MT] Malta              1414\n",
       "[GR] Greece             1373\n",
       "[LV] Latvia             1321\n",
       "[RO] Romania            1261\n",
       "[PT] Portugal           1246\n",
       "[HU] Hungary             919\n",
       "[EE] Estonia             885\n",
       "[HR] Croatia             746\n",
       "[LT] Lithuania           666\n",
       "[SI] Slovenia            395\n",
       "[CY] Cyprus              234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['S_NCA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEC_TYPE_CFI\n",
       "Z                                                9\n",
       "[DE] Structured debt (no capital protection)     6\n",
       "[DM] Other debt                                  3\n",
       "[DS] Structured debt (capital protection)        1\n",
       "[DT] MTN                                         2\n",
       "[D] Debt                                         2\n",
       "[ES] Shares                                      3\n",
       "[EY] Structured instruments (participation)      3\n",
       "[E] Equity                                       6\n",
       "[RF] Mini-future certificates                    3\n",
       "[RW] Warrants                                    3\n",
       "[R] Entitlement (rights)                        11\n",
       "[SCRT] Securities                                5\n",
       "[ZALL] All records if applicable                 5\n",
       "[ZNAV] CFI not available                         3\n",
       "Name: rfr_outlier, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[(pdf['S_NCA'] == '[DE] Germany') & (pdf['rfr_outlier'] == True)].groupby('SEC_TYPE_CFI')['rfr_outlier'].sum().loc[lambda s: s>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pdf[\n",
    "    (pdf['S_NCA']   == '[DE] Germany') &\n",
    "    (pdf['SEC_TYPE_CFI'] == '[DM] Other debt')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>S_NCA</th>\n",
       "      <th>SEC_TYPE_CFI</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>quarter_date</th>\n",
       "      <th>rfr_outlier</th>\n",
       "      <th>inherited_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96715</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S12.Z.Z.Z...</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96716</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.ZALL.Z.Z....</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96717</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A1_Z.Z.Z.Z...</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96718</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A6.Z.Z.Z.Z...</td>\n",
       "      <td>2021-Q2</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96719</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.DE.Z.Z.Z.Z...</td>\n",
       "      <td>2021-Q2</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96914</th>\n",
       "      <td>PROSP3.MV.Q.DE.Z.Z.Z.Z.Z.DM.Z.S11.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>57357036.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96915</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S12.Z.Z.Z...</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96916</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A1.Z.Z.Z.Z...</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96917</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S11.Z.Z.Z...</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96918</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.ZALL.Z.Z....</td>\n",
       "      <td>2025-Q1</td>\n",
       "      <td>[DE] Germany</td>\n",
       "      <td>[DM] Other debt</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     KEY TIME_PERIOD  \\\n",
       "96715  PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S12.Z.Z.Z...     2021-Q1   \n",
       "96716  PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.ZALL.Z.Z....     2021-Q1   \n",
       "96717  PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A1_Z.Z.Z.Z...     2021-Q1   \n",
       "96718  PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A6.Z.Z.Z.Z...     2021-Q2   \n",
       "96719  PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.DE.Z.Z.Z.Z...     2021-Q2   \n",
       "...                                                  ...         ...   \n",
       "96914      PROSP3.MV.Q.DE.Z.Z.Z.Z.Z.DM.Z.S11.Z.Z.Z.Z.Z.Z     2025-Q1   \n",
       "96915  PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S12.Z.Z.Z...     2025-Q1   \n",
       "96916  PROSP3.NUM_ISSUER.Q.DE.Z.Z.Z.Z.Z.DM.A1.Z.Z.Z.Z...     2025-Q1   \n",
       "96917  PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.S11.Z.Z.Z...     2025-Q1   \n",
       "96918  PROSP3.NUM_INSTR.Q.DE.Z.Z.Z.Z.Z.DM.Z.ZALL.Z.Z....     2025-Q1   \n",
       "\n",
       "              S_NCA     SEC_TYPE_CFI   OBS_VALUE quarter_date  rfr_outlier  \\\n",
       "96715  [DE] Germany  [DM] Other debt        14.0   2021-01-01        False   \n",
       "96716  [DE] Germany  [DM] Other debt        14.0   2021-01-01        False   \n",
       "96717  [DE] Germany  [DM] Other debt         1.0   2021-01-01        False   \n",
       "96718  [DE] Germany  [DM] Other debt         3.0   2021-04-01        False   \n",
       "96719  [DE] Germany  [DM] Other debt         3.0   2021-04-01        False   \n",
       "...             ...              ...         ...          ...          ...   \n",
       "96914  [DE] Germany  [DM] Other debt  57357036.0   2025-01-01        False   \n",
       "96915  [DE] Germany  [DM] Other debt        21.0   2025-01-01        False   \n",
       "96916  [DE] Germany  [DM] Other debt         2.0   2025-01-01        False   \n",
       "96917  [DE] Germany  [DM] Other debt         8.0   2025-01-01        False   \n",
       "96918  [DE] Germany  [DM] Other debt        29.0   2025-01-01        False   \n",
       "\n",
       "       inherited_outlier  \n",
       "96715               True  \n",
       "96716               True  \n",
       "96717               True  \n",
       "96718               True  \n",
       "96719               True  \n",
       "...                  ...  \n",
       "96914               True  \n",
       "96915               True  \n",
       "96916               True  \n",
       "96917               True  \n",
       "96918               True  \n",
       "\n",
       "[204 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(\n",
    "    sub['quarter_date'],\n",
    "    sub['OBS_VALUE'],\n",
    "    '-o',\n",
    "    label='True OBS_VALUE'\n",
    ")\n",
    "\n",
    "out = sub[sub['rfr_outlier']]\n",
    "plt.scatter(\n",
    "    out['quarter_date'],\n",
    "    out['OBS_VALUE'],\n",
    "    s=100,\n",
    "    color='red',\n",
    "    label='RFR outliers'\n",
    ")\n",
    "\n",
    "plt.title(\"Debt in germ over time\")\n",
    "plt.xlabel(\"Quarter\")\n",
    "plt.ylabel(\"OBS_VALUE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = pd.read_excel('Country Mapping.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>DIRECT_PARENT</th>\n",
       "      <th>LEVEL_PARENT</th>\n",
       "      <th>ORDER</th>\n",
       "      <th>CODE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Filter not applied for location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZNAV</td>\n",
       "      <td>Z</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Country not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1</td>\n",
       "      <td>Z</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1_Z</td>\n",
       "      <td>A1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World - Undetermined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1_TRNS</td>\n",
       "      <td>A1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World - International organisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>EH</td>\n",
       "      <td>UN015</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Western Sahara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>YE</td>\n",
       "      <td>UN202</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>ZM</td>\n",
       "      <td>UN202</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zambia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UN202</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>SZ</td>\n",
       "      <td>UN202</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eswatini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CODE DIRECT_PARENT  LEVEL_PARENT  ORDER  \\\n",
       "0          Z           NaN             0    NaN   \n",
       "1       ZNAV             Z             1    NaN   \n",
       "2         A1             Z             1    NaN   \n",
       "3       A1_Z            A1             2    NaN   \n",
       "4    A1_TRNS            A1             2    NaN   \n",
       "..       ...           ...           ...    ...   \n",
       "292       EH         UN015             5    NaN   \n",
       "293       YE         UN202             5    NaN   \n",
       "294       ZM         UN202             5    NaN   \n",
       "295       ZW         UN202             5    NaN   \n",
       "296       SZ         UN202             5    NaN   \n",
       "\n",
       "                       CODE_DESCRIPTION  \n",
       "0      Filter not applied for location   \n",
       "1                 Country not available  \n",
       "2                                 World  \n",
       "3                  World - Undetermined  \n",
       "4    World - International organisation  \n",
       "..                                  ...  \n",
       "292                      Western Sahara  \n",
       "293                               Yemen  \n",
       "294                              Zambia  \n",
       "295                            Zimbabwe  \n",
       "296                            Eswatini  \n",
       "\n",
       "[297 rows x 5 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Z': nan,\n",
       " 'ZNAV': 'Z',\n",
       " 'A1': 'Z',\n",
       " 'A1_Z': 'A1',\n",
       " 'A1_TRNS': 'A1',\n",
       " 'A1_OTHR': 'A1',\n",
       " 'A6': 'A1',\n",
       " 'A6_Z': 'A6',\n",
       " 'A6_TRNS': 'A6',\n",
       " 'A6_OTHR': 'A6',\n",
       " 'A0': 'A6',\n",
       " 'V5': 'A6',\n",
       " 'V5_Z': 'V5',\n",
       " 'V5_TRNS': 'V5',\n",
       " 'K0': 'V5',\n",
       " 'I8': 'V5',\n",
       " 'I8_Z': 'I8',\n",
       " 'I8_TRNS': 'I8',\n",
       " 'I8_OTHR': 'I8',\n",
       " 'ROW': 'A1',\n",
       " 'E2': 'ROW',\n",
       " 'UN002': 'ROW',\n",
       " 'UN015': 'UN002',\n",
       " 'UN017': 'UN002',\n",
       " 'UN018': 'UN002',\n",
       " 'UN202': 'UN002',\n",
       " 'UN011': 'UN202',\n",
       " 'UN014': 'UN202',\n",
       " 'UN009': 'ROW',\n",
       " 'UN053': 'UN009',\n",
       " 'UN057': 'UN009',\n",
       " 'UN061': 'UN009',\n",
       " 'UN010': 'ROW',\n",
       " 'UN019': 'ROW',\n",
       " 'UN021': 'UN019',\n",
       " 'UN419': 'UN019',\n",
       " 'UN005': 'UN419',\n",
       " 'UN013': 'UN419',\n",
       " 'UN029': 'UN419',\n",
       " 'UN142': 'ROW',\n",
       " 'UN030': 'UN142',\n",
       " 'UN034': 'UN142',\n",
       " 'UN035': 'UN142',\n",
       " 'UN143': 'UN142',\n",
       " 'UN145': 'UN142',\n",
       " 'IS': 'A0',\n",
       " 'LI': 'A0',\n",
       " 'NO': 'A0',\n",
       " 'GB': 'E2',\n",
       " 'MK': 'E2',\n",
       " 'AX': 'E2',\n",
       " 'AL': 'E2',\n",
       " 'AD': 'E2',\n",
       " 'BY': 'E2',\n",
       " 'BA': 'E2',\n",
       " 'GI': 'E2',\n",
       " 'GG': 'E2',\n",
       " 'VA': 'E2',\n",
       " 'IM': 'E2',\n",
       " 'JE': 'E2',\n",
       " 'XK': 'E2',\n",
       " 'MD': 'E2',\n",
       " 'MC': 'E2',\n",
       " 'ME': 'E2',\n",
       " 'RU': 'E2',\n",
       " 'SM': 'E2',\n",
       " 'RS': 'E2',\n",
       " 'CH': 'E2',\n",
       " 'UA': 'E2',\n",
       " 'AT': 'I8',\n",
       " 'BE': 'I8',\n",
       " 'CY': 'I8',\n",
       " 'EE': 'I8',\n",
       " 'FI': 'I8',\n",
       " 'FR': 'I8',\n",
       " 'DE': 'I8',\n",
       " 'GR': 'I8',\n",
       " 'IE': 'I8',\n",
       " 'IT': 'I8',\n",
       " 'LV': 'I8',\n",
       " 'LT': 'I8',\n",
       " 'LU': 'I8',\n",
       " 'MT': 'I8',\n",
       " 'NL': 'I8',\n",
       " 'PT': 'I8',\n",
       " 'SK': 'I8',\n",
       " 'SI': 'I8',\n",
       " 'ES': 'I8',\n",
       " 'CZ': 'K0',\n",
       " 'BG': 'K0',\n",
       " 'HR': 'K0',\n",
       " 'DK': 'K0',\n",
       " 'HU': 'K0',\n",
       " 'PL': 'K0',\n",
       " 'RO': 'K0',\n",
       " 'SE': 'K0',\n",
       " 'AR': 'UN005',\n",
       " 'BO': 'UN005',\n",
       " 'BR': 'UN005',\n",
       " 'CL': 'UN005',\n",
       " 'CO': 'UN005',\n",
       " 'EC': 'UN005',\n",
       " 'PY': 'UN005',\n",
       " 'PE': 'UN005',\n",
       " 'UY': 'UN005',\n",
       " 'VE': 'UN005',\n",
       " 'AQ': 'UN010',\n",
       " 'BJ': 'UN011',\n",
       " 'GH': 'UN011',\n",
       " 'NE': 'UN011',\n",
       " 'NG': 'UN011',\n",
       " 'SN': 'UN011',\n",
       " 'BZ': 'UN013',\n",
       " 'CR': 'UN013',\n",
       " 'SV': 'UN013',\n",
       " 'GT': 'UN013',\n",
       " 'HN': 'UN013',\n",
       " 'MX': 'UN013',\n",
       " 'PA': 'UN013',\n",
       " 'PZ': 'UN013',\n",
       " 'ET': 'UN014',\n",
       " 'SC': 'UN014',\n",
       " 'SH': 'UN014',\n",
       " 'DZ': 'UN015',\n",
       " 'EG': 'UN015',\n",
       " 'MA': 'UN015',\n",
       " 'AO': 'UN017',\n",
       " 'GQ': 'UN017',\n",
       " 'ZA': 'UN018',\n",
       " 'BM': 'UN021',\n",
       " 'CA': 'UN021',\n",
       " 'US': 'UN021',\n",
       " 'AI': 'UN029',\n",
       " 'AG': 'UN029',\n",
       " 'AW': 'UN029',\n",
       " 'BS': 'UN029',\n",
       " 'BB': 'UN029',\n",
       " 'KY': 'UN029',\n",
       " 'CU': 'UN029',\n",
       " 'DM': 'UN029',\n",
       " 'DO': 'UN029',\n",
       " 'JM': 'UN029',\n",
       " 'PR': 'UN029',\n",
       " 'VI': 'UN029',\n",
       " 'VG': 'UN029',\n",
       " 'CN': 'UN030',\n",
       " 'HK': 'UN030',\n",
       " 'JP': 'UN030',\n",
       " 'KP': 'UN030',\n",
       " 'KR': 'UN030',\n",
       " 'MO': 'UN030',\n",
       " 'TW': 'UN030',\n",
       " 'AF': 'UN034',\n",
       " 'BD': 'UN034',\n",
       " 'IN': 'UN034',\n",
       " 'IR': 'UN034',\n",
       " 'PK': 'UN034',\n",
       " 'LK': 'UN034',\n",
       " 'ID': 'UN035',\n",
       " 'MY': 'UN035',\n",
       " 'MM': 'UN035',\n",
       " 'PH': 'UN035',\n",
       " 'SG': 'UN035',\n",
       " 'TH': 'UN035',\n",
       " 'VN': 'UN035',\n",
       " 'AU': 'UN053',\n",
       " 'NZ': 'UN053',\n",
       " 'NF': 'UN053',\n",
       " 'UM': 'UN061',\n",
       " 'AS': 'UN061',\n",
       " 'KZ': 'UN143',\n",
       " 'AM': 'UN145',\n",
       " 'AZ': 'UN145',\n",
       " 'BH': 'UN145',\n",
       " 'GE': 'UN145',\n",
       " 'IQ': 'UN145',\n",
       " 'IL': 'UN145',\n",
       " 'KW': 'UN145',\n",
       " 'OM': 'UN145',\n",
       " 'PS': 'UN145',\n",
       " 'QA': 'UN145',\n",
       " 'SA': 'UN145',\n",
       " 'TR': 'UN145',\n",
       " 'AE': 'UN145',\n",
       " 'BT': 'UN034',\n",
       " 'BQ': 'UN029',\n",
       " 'BW': 'UN018',\n",
       " 'BV': 'UN419',\n",
       " 'IO': 'UN202',\n",
       " 'BN': 'UN035',\n",
       " 'BF': 'UN202',\n",
       " 'BI': 'UN202',\n",
       " 'CV': 'UN202',\n",
       " 'KH': 'UN035',\n",
       " 'CM': 'UN202',\n",
       " 'CF': 'UN202',\n",
       " 'TD': 'UN202',\n",
       " 'CX': 'UN053',\n",
       " 'CC': 'UN053',\n",
       " 'KM': 'UN202',\n",
       " 'CG': 'UN202',\n",
       " 'CD': 'UN202',\n",
       " 'CK': 'UN061',\n",
       " 'CI': 'UN202',\n",
       " 'CW': 'UN029',\n",
       " 'DJ': 'UN202',\n",
       " 'ER': 'UN202',\n",
       " 'FK': 'UN005',\n",
       " 'FO': 'E2',\n",
       " 'FJ': 'UN057',\n",
       " 'GF': 'UN005',\n",
       " 'PF': 'UN061',\n",
       " 'TF': 'UN202',\n",
       " 'GA': 'UN202',\n",
       " 'GM': 'UN202',\n",
       " 'GL': 'UN021',\n",
       " 'GD': 'UN029',\n",
       " 'GP': 'UN029',\n",
       " 'GU': 'UN057',\n",
       " 'GN': 'UN202',\n",
       " 'GW': 'UN202',\n",
       " 'GY': 'UN005',\n",
       " 'HT': 'UN029',\n",
       " 'HM': 'UN053',\n",
       " 'JO': 'UN145',\n",
       " 'KE': 'UN202',\n",
       " 'KI': 'UN057',\n",
       " 'KG': 'UN143',\n",
       " 'LA': 'UN035',\n",
       " 'LB': 'UN145',\n",
       " 'LS': 'UN202',\n",
       " 'LR': 'UN202',\n",
       " 'LY': 'UN015',\n",
       " 'MG': 'UN202',\n",
       " 'MW': 'UN202',\n",
       " 'MV': 'UN034',\n",
       " 'ML': 'UN202',\n",
       " 'MH': 'UN057',\n",
       " 'MQ': 'UN029',\n",
       " 'MR': 'UN202',\n",
       " 'MU': 'UN202',\n",
       " 'YT': 'UN202',\n",
       " 'FM': 'UN057',\n",
       " 'MN': 'UN030',\n",
       " 'MS': 'UN029',\n",
       " 'MZ': 'UN202',\n",
       " 'NAMIBIA': 'UN202',\n",
       " 'NR': 'UN057',\n",
       " 'NP': 'UN034',\n",
       " 'AN': 'UN029',\n",
       " 'NC': 'UN057',\n",
       " 'NI': 'UN013',\n",
       " 'NU': 'UN061',\n",
       " 'MP': 'UN057',\n",
       " 'PW': 'UN057',\n",
       " 'PG': 'UN057',\n",
       " 'PN': 'UN061',\n",
       " 'RE': 'UN202',\n",
       " 'RW': 'UN202',\n",
       " 'BL': 'UN029',\n",
       " 'KN': 'UN029',\n",
       " 'LC': 'UN029',\n",
       " 'MF': 'UN029',\n",
       " 'PM': 'UN021',\n",
       " 'VC': 'UN029',\n",
       " 'WS': 'UN061',\n",
       " 'ST': 'UN202',\n",
       " 'SL': 'UN202',\n",
       " 'SX': 'UN029',\n",
       " 'SB': 'UN057',\n",
       " 'SO': 'UN202',\n",
       " 'GS': 'UN005',\n",
       " 'SS': 'UN202',\n",
       " 'SD': 'UN202',\n",
       " 'SR': 'UN005',\n",
       " 'SJ': 'E2',\n",
       " 'SY': 'UN145',\n",
       " 'TJ': 'UN143',\n",
       " 'TZ': 'UN202',\n",
       " 'TL': 'UN035',\n",
       " 'TG': 'UN202',\n",
       " 'TK': 'UN061',\n",
       " 'TO': 'UN061',\n",
       " 'TT': 'UN029',\n",
       " 'TN': 'UN015',\n",
       " 'TM': 'UN143',\n",
       " 'TC': 'UN029',\n",
       " 'TV': 'UN061',\n",
       " 'UG': 'UN202',\n",
       " 'UZ': 'UN143',\n",
       " 'VU': 'UN057',\n",
       " 'WF': 'UN061',\n",
       " 'EH': 'UN015',\n",
       " 'YE': 'UN202',\n",
       " 'ZM': 'UN202',\n",
       " 'ZW': 'UN202',\n",
       " 'SZ': 'UN202'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_map = dict(zip(map['CODE'], map['DIRECT_PARENT']))\n",
    "parent_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>S_NCA</th>\n",
       "      <th>SEC_TYPE_CFI</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>quarter_date</th>\n",
       "      <th>rfr_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z...</td>\n",
       "      <td>2023-Q3</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>[ED] DR equities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.ZNAV.Z.Z....</td>\n",
       "      <td>2023-Q3</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>[ED] DR equities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.ROW.Z.Z.Z....</td>\n",
       "      <td>2023-Q3</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>[ED] DR equities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z.Z.Z</td>\n",
       "      <td>2023-Q3</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>[ED] DR equities</td>\n",
       "      <td>1834864.6</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.UN019.Z.Z....</td>\n",
       "      <td>2023-Q3</td>\n",
       "      <td>[A0] EEA3</td>\n",
       "      <td>[ED] DR equities</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151323</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.ROW.Z.Z....</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151324</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.Z.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151325</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.ZALL.Z....</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151326</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.A1.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151327</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.LU.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151328 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      KEY TIME_PERIOD  \\\n",
       "0       PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z...     2023-Q3   \n",
       "1       PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.ZNAV.Z.Z....     2023-Q3   \n",
       "2       PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.ROW.Z.Z.Z....     2023-Q3   \n",
       "3             PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q3   \n",
       "4       PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.UN019.Z.Z....     2023-Q3   \n",
       "...                                                   ...         ...   \n",
       "151323  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.ROW.Z.Z....     2025-Q2   \n",
       "151324  PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.Z.Z.Z.Z...     2025-Q2   \n",
       "151325  PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.ZALL.Z....     2025-Q2   \n",
       "151326  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.A1.Z.Z.Z...     2025-Q2   \n",
       "151327  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.LU.Z.Z.Z...     2025-Q2   \n",
       "\n",
       "            S_NCA                      SEC_TYPE_CFI  OBS_VALUE quarter_date  \\\n",
       "0       [A0] EEA3                  [ED] DR equities        1.0   2023-07-01   \n",
       "1       [A0] EEA3                  [ED] DR equities        1.0   2023-07-01   \n",
       "2       [A0] EEA3                  [ED] DR equities        1.0   2023-07-01   \n",
       "3       [A0] EEA3                  [ED] DR equities  1834864.6   2023-07-01   \n",
       "4       [A0] EEA3                  [ED] DR equities        1.0   2023-07-01   \n",
       "...           ...                               ...        ...          ...   \n",
       "151323  [V5] EU27  [ZALL] All records if applicable        1.0   2025-04-01   \n",
       "151324  [V5] EU27  [ZALL] All records if applicable       24.0   2025-04-01   \n",
       "151325  [V5] EU27  [ZALL] All records if applicable       24.0   2025-04-01   \n",
       "151326  [V5] EU27  [ZALL] All records if applicable        4.0   2025-04-01   \n",
       "151327  [V5] EU27  [ZALL] All records if applicable        1.0   2025-04-01   \n",
       "\n",
       "        rfr_outlier  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "...             ...  \n",
       "151323        False  \n",
       "151324        False  \n",
       "151325        False  \n",
       "151326        False  \n",
       "151327        False  \n",
       "\n",
       "[151328 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 KEY TIME_PERIOD      S_NCA  \\\n",
      "0  PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z...     2023-Q3  [A0] EEA3   \n",
      "1  PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.ZNAV.Z.Z....     2023-Q3  [A0] EEA3   \n",
      "2  PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.ROW.Z.Z.Z....     2023-Q3  [A0] EEA3   \n",
      "3        PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z.Z.Z     2023-Q3  [A0] EEA3   \n",
      "4  PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.UN019.Z.Z....     2023-Q3  [A0] EEA3   \n",
      "5     PROSP3.MV.Q.A0.Z.Z.Z.Z.Z.ED.Z.ZNAV.Z.Z.Z.Z.Z.Z     2023-Q3  [A0] EEA3   \n",
      "6  PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.A1.Z.Z.Z.Z...     2024-Q1  [A0] EEA3   \n",
      "7  PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.Z.Z.Z.Z.Z...     2024-Q1  [A0] EEA3   \n",
      "8  PROSP3.NUM_INSTR.Q.A0.Z.Z.Z.Z.Z.ED.Z.ZNAV.Z.Z....     2024-Q1  [A0] EEA3   \n",
      "9  PROSP3.NUM_ISSUER.Q.A0.Z.Z.Z.Z.Z.ED.ROW.Z.Z.Z....     2024-Q1  [A0] EEA3   \n",
      "\n",
      "       SEC_TYPE_CFI  OBS_VALUE  rfr_outlier  inherited_outlier  \n",
      "0  [ED] DR equities        1.0        False              False  \n",
      "1  [ED] DR equities        1.0        False              False  \n",
      "2  [ED] DR equities        1.0        False              False  \n",
      "3  [ED] DR equities  1834864.6        False              False  \n",
      "4  [ED] DR equities        1.0        False              False  \n",
      "5  [ED] DR equities  1834864.6        False              False  \n",
      "6  [ED] DR equities        1.0        False              False  \n",
      "7  [ED] DR equities        1.0        False              False  \n",
      "8  [ED] DR equities        1.0        False              False  \n",
      "9  [ED] DR equities        1.0        False              False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 0) (re)extract the raw code if you haven’t yet\n",
    "pdf['code'] = pdf['S_NCA'].str.extract(r'\\[([^\\]]+)\\]')\n",
    "\n",
    "# 1) Build parent_map\n",
    "parent_map = dict(zip(map['CODE'], map['DIRECT_PARENT']))\n",
    "\n",
    "# 2) Define a helper to walk up from any code to its ancestors\n",
    "def get_ancestors(code):\n",
    "    anc = []\n",
    "    p = parent_map.get(code)\n",
    "    while p and pd.notna(p):\n",
    "        anc.append(p)\n",
    "        p = parent_map.get(p)\n",
    "    return anc\n",
    "\n",
    "# 3) Build a small DataFrame of all (TIME_PERIOD, SEC_TYPE_CFI, code, ancestors)\n",
    "#    for only the rows the RFR actually flagged\n",
    "flagged = pdf.loc[pdf['rfr_outlier'], ['TIME_PERIOD','SEC_TYPE_CFI','code']].copy()\n",
    "flagged['ancestors'] = flagged['code'].map(get_ancestors)\n",
    "\n",
    "# 4) Explode that list so each ancestor is its own row\n",
    "flagged_expanded = (\n",
    "    flagged\n",
    "    .explode('ancestors')\n",
    "    .dropna(subset=['ancestors'])\n",
    "    .rename(columns={'ancestors':'ancestor_code'})\n",
    "    # now columns: TIME_PERIOD, SEC_TYPE_CFI, code, ancestor_code\n",
    ")\n",
    "\n",
    "# 5) Initialize the new flag\n",
    "pdf['inherited_outlier'] = False\n",
    "\n",
    "# 6) Any row whose (TIME_PERIOD, SEC_TYPE_CFI, code) matches a flagged ancestor\n",
    "#    becomes inherited_outlier=True\n",
    "mask = pd.merge(\n",
    "    pdf,\n",
    "    flagged_expanded[['TIME_PERIOD','SEC_TYPE_CFI','ancestor_code']],\n",
    "    left_on  = ['TIME_PERIOD','SEC_TYPE_CFI','code'],\n",
    "    right_on = ['TIME_PERIOD','SEC_TYPE_CFI','ancestor_code'],\n",
    "    how      = 'left',\n",
    "    indicator= '_hit'\n",
    ")['_hit'] == 'both'\n",
    "\n",
    "pdf.loc[mask, 'inherited_outlier'] = True\n",
    "\n",
    "# 7) (Optional) clean up\n",
    "pdf = pdf.drop(columns=['code'])\n",
    "\n",
    "# 8) Look at your two flags\n",
    "print(pdf[['KEY','TIME_PERIOD','S_NCA','SEC_TYPE_CFI','OBS_VALUE',\n",
    "           'rfr_outlier','inherited_outlier']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>S_NCA</th>\n",
       "      <th>SEC_TYPE_CFI</th>\n",
       "      <th>OBS_VALUE</th>\n",
       "      <th>quarter_date</th>\n",
       "      <th>rfr_outlier</th>\n",
       "      <th>inherited_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.CZ.Z.Z.Z.Z....</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[A1] World</td>\n",
       "      <td>Z</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.E2.Z.Z.Z.Z....</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[A1] World</td>\n",
       "      <td>Z</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.HR.Z.Z.Z.Z....</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[A1] World</td>\n",
       "      <td>Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.SE.Z.Z.Z.Z....</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[A1] World</td>\n",
       "      <td>Z</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.UN142.Z.Z.Z...</td>\n",
       "      <td>2021-Q1</td>\n",
       "      <td>[A1] World</td>\n",
       "      <td>Z</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151323</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.ROW.Z.Z....</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151324</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.Z.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151325</th>\n",
       "      <td>PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.ZALL.Z....</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151326</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.A1.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151327</th>\n",
       "      <td>PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.LU.Z.Z.Z...</td>\n",
       "      <td>2025-Q2</td>\n",
       "      <td>[V5] EU27</td>\n",
       "      <td>[ZALL] All records if applicable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140588 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      KEY TIME_PERIOD  \\\n",
       "19      PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.CZ.Z.Z.Z.Z....     2021-Q1   \n",
       "20      PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.E2.Z.Z.Z.Z....     2021-Q1   \n",
       "21      PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.HR.Z.Z.Z.Z....     2021-Q1   \n",
       "22      PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.SE.Z.Z.Z.Z....     2021-Q1   \n",
       "23      PROSP3.NUM_ISSUER.Q.A1.Z.Z.Z.Z.Z.Z.UN142.Z.Z.Z...     2021-Q1   \n",
       "...                                                   ...         ...   \n",
       "151323  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.ROW.Z.Z....     2025-Q2   \n",
       "151324  PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.Z.Z.Z.Z...     2025-Q2   \n",
       "151325  PROSP3.NUM_INSTR.Q.V5.Z.Z.Z.Z.Z.ZALL.Z.ZALL.Z....     2025-Q2   \n",
       "151326  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.A1.Z.Z.Z...     2025-Q2   \n",
       "151327  PROSP3.NUM_ISSUER.Q.V5.Z.Z.Z.Z.Z.ZALL.LU.Z.Z.Z...     2025-Q2   \n",
       "\n",
       "             S_NCA                      SEC_TYPE_CFI  OBS_VALUE quarter_date  \\\n",
       "19      [A1] World                                 Z       35.0   2021-01-01   \n",
       "20      [A1] World                                 Z       41.0   2021-01-01   \n",
       "21      [A1] World                                 Z        1.0   2021-01-01   \n",
       "22      [A1] World                                 Z      108.0   2021-01-01   \n",
       "23      [A1] World                                 Z       17.0   2021-01-01   \n",
       "...            ...                               ...        ...          ...   \n",
       "151323   [V5] EU27  [ZALL] All records if applicable        1.0   2025-04-01   \n",
       "151324   [V5] EU27  [ZALL] All records if applicable       24.0   2025-04-01   \n",
       "151325   [V5] EU27  [ZALL] All records if applicable       24.0   2025-04-01   \n",
       "151326   [V5] EU27  [ZALL] All records if applicable        4.0   2025-04-01   \n",
       "151327   [V5] EU27  [ZALL] All records if applicable        1.0   2025-04-01   \n",
       "\n",
       "        rfr_outlier  inherited_outlier  \n",
       "19            False               True  \n",
       "20            False               True  \n",
       "21            False               True  \n",
       "22            False               True  \n",
       "23            False               True  \n",
       "...             ...                ...  \n",
       "151323        False               True  \n",
       "151324        False               True  \n",
       "151325        False               True  \n",
       "151326        False               True  \n",
       "151327        False               True  \n",
       "\n",
       "[140588 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[pdf['inherited_outlier']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay so this makes sense. but i still need to be careful about the way these are flagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the code is structured right now, the whole hierarchy is flagged if a nember is flagged. Maybe this is not a correct approach bcs world gets flagged?? maybe i should flag only direct parentship??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If i want to mao to only the immediate parent:\n",
    "'''\n",
    "flagged = pdf.loc[pdf['rfr_outlier'], ['TIME_PERIOD','SEC_TYPE_CFI','code']].copy()\n",
    "flagged['parent'] = flagged['code'].map(parent_map)          # only one level up\n",
    "flagged_expanded = flagged.dropna(subset=['parent']).rename(\n",
    "    columns={'parent':'ancestor_code'}\n",
    ")\n",
    "mask = pd.merge(\n",
    "    pdf,\n",
    "    flagged_expanded[['TIME_PERIOD','SEC_TYPE_CFI','ancestor_code']],\n",
    "    left_on  = ['TIME_PERIOD','SEC_TYPE_CFI','code'],\n",
    "    right_on = ['TIME_PERIOD','SEC_TYPE_CFI','ancestor_code'],\n",
    "    how      = 'left',\n",
    "    indicator= '_hit'\n",
    ")['_hit'] == 'both'\n",
    "\n",
    "pdf['inherited_outlier'] = False\n",
    "pdf.loc[mask, 'inherited_outlier'] = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask Jordi abt the further granularity data to perform the actual time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-04-01 00:00:00')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['quarter_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╭──────────────────────────────────── IndexWarning ────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Series has an unsupported index type (not pandas DatetimeIndex or RangeIndex). The   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> index will be replaced by a RangeIndex starting from 0 with a step of 1. To avoid    <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> this warning, ensure that `y.index` is a DatetimeIndex with a frequency or a         <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> RangeIndex.                                                                          <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>                                                                                      <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Category : IndexWarning                                                              <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Location :                                                                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> /opt/anaconda3/envs/datasci/lib/python3.12/site-packages/skforecast/utils/utils.py:1 <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> 411                                                                                  <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Suppress : warnings.simplefilter('ignore', category=IndexWarning)                    <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╰──────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;214m╭─\u001b[0m\u001b[38;5;214m───────────────────────────────────\u001b[0m\u001b[38;5;214m IndexWarning \u001b[0m\u001b[38;5;214m───────────────────────────────────\u001b[0m\u001b[38;5;214m─╮\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Series has an unsupported index type (not pandas DatetimeIndex or RangeIndex). The   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m index will be replaced by a RangeIndex starting from 0 with a step of 1. To avoid    \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m this warning, ensure that `y.index` is a DatetimeIndex with a frequency or a         \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m RangeIndex.                                                                          \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m                                                                                      \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Category : IndexWarning                                                              \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Location :                                                                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m /opt/anaconda3/envs/datasci/lib/python3.12/site-packages/skforecast/utils/utils.py:1 \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m 411                                                                                  \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Suppress : warnings.simplefilter('ignore', category=IndexWarning)                    \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m╰──────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╭──────────────────────────────────── IndexWarning ────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> `last_window` has an unsupported index type (not pandas DatetimeIndex or             <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> RangeIndex). The index will be replaced by a RangeIndex starting from 0 with a step  <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> of 1. To avoid this warning, ensure that `last_window.index` is a DatetimeIndex with <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> a frequency or a RangeIndex.                                                         <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>                                                                                      <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Category : IndexWarning                                                              <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Location :                                                                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> /opt/anaconda3/envs/datasci/lib/python3.12/site-packages/skforecast/utils/utils.py:1 <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> 468                                                                                  <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Suppress : warnings.simplefilter('ignore', category=IndexWarning)                    <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╰──────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;214m╭─\u001b[0m\u001b[38;5;214m───────────────────────────────────\u001b[0m\u001b[38;5;214m IndexWarning \u001b[0m\u001b[38;5;214m───────────────────────────────────\u001b[0m\u001b[38;5;214m─╮\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m `last_window` has an unsupported index type (not pandas DatetimeIndex or             \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m RangeIndex). The index will be replaced by a RangeIndex starting from 0 with a step  \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m of 1. To avoid this warning, ensure that `last_window.index` is a DatetimeIndex with \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m a frequency or a RangeIndex.                                                         \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m                                                                                      \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Category : IndexWarning                                                              \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Location :                                                                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m /opt/anaconda3/envs/datasci/lib/python3.12/site-packages/skforecast/utils/utils.py:1 \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m 468                                                                                  \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Suppress : warnings.simplefilter('ignore', category=IndexWarning)                    \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m╰──────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skforecast.recursive import ForecasterRecursive\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "train_start = pdf['quarter_date'].min()\n",
    "train_end = '2024-09-01'\n",
    "test_start = '2024-09-01'\n",
    "test_end = pdf['quarter_date'].max()\n",
    "\n",
    "df = pdf\n",
    "\n",
    "df['quarter_date'] = pd.to_datetime(df['quarter_date'])\n",
    "\n",
    "forecaster = ForecasterRecursive(\n",
    "    regressor = DecisionTreeRegressor(random_state=123),\n",
    "    lags      = 30\n",
    ")\n",
    "\n",
    "mask       = (df['quarter_date'] >= train_start) & (df['quarter_date'] <= train_end)\n",
    "y_train    = df.loc[mask, 'OBS_VALUE']\n",
    "forecaster.fit(y = y_train)\n",
    "\n",
    "mask_test  = (df['quarter_date'] >= test_start) & (df['quarter_date'] <= test_end)\n",
    "n_steps    = mask_test.sum()\n",
    "predictions = forecaster.predict(steps = n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "n_periods must be an int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m n_test     \u001b[38;5;241m=\u001b[39m test_mask\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      9\u001b[0m arima_train \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mpredict_in_sample()\n\u001b[0;32m---> 10\u001b[0m arima_test  \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mpredict(n_periods\u001b[38;5;241m=\u001b[39mn_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pmdarima/utils/metaestimators.py:53\u001b[0m, in \u001b[0;36m_IffHasDelegate.__get__.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         attrgetter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelegate_names[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])(obj)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# lambda, but not partial, allows help() to work with update_wrapper\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# update the docstring of the returned function\u001b[39;00m\n\u001b[1;32m     55\u001b[0m update_wrapper(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pmdarima/arima/auto.py:243\u001b[0m, in \u001b[0;36mAutoARIMA.predict\u001b[0;34m(self, n_periods, X, return_conf_int, alpha)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;129m@if_has_delegate\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m    242\u001b[0m ):\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    244\u001b[0m         n_periods\u001b[38;5;241m=\u001b[39mn_periods,\n\u001b[1;32m    245\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    246\u001b[0m         return_conf_int\u001b[38;5;241m=\u001b[39mreturn_conf_int,\n\u001b[1;32m    247\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    248\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datasci/lib/python3.12/site-packages/pmdarima/arima/arima.py:782\u001b[0m, in \u001b[0;36mARIMA.predict\u001b[0;34m(self, n_periods, X, return_conf_int, alpha, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marima_res_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n_periods, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 782\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_periods must be an int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# if we fit with exog, make sure one was passed:\u001b[39;00m\n\u001b[1;32m    785\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exog(X)  \u001b[38;5;66;03m# type: np.ndarray\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: n_periods must be an int"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 23:48:55 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 281900 ms exceeds timeout 120000 ms\n",
      "25/04/21 23:48:55 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/04/21 23:48:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:48:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:48:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:48:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:48:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:48:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:49:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:50:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:51:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:52:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:53:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:54:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:55:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:56:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:57:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:57:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:36 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:36 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:46 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:46 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:57:56 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:57:56 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/21 23:58:06 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:06 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:842)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.1.98:65200\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/21 23:58:26 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "import pmdarima as pm\n",
    "\n",
    "train_mask = (df['quarter_date'] >= train_start) & (df['quarter_date'] <= train_end)\n",
    "y_train    = df.loc[train_mask, 'OBS_VALUE']\n",
    "arima = pm.AutoARIMA(seasonal=False)\n",
    "arima.fit(y_train)\n",
    "test_mask  = (df['quarter_date'] >= test_start) & (df['quarter_date'] <= test_end)\n",
    "n_test     = test_mask.sum()\n",
    "arima_train = arima.predict_in_sample()\n",
    "#arima_test  = arima.predict(n_periods=n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "df.loc[test_start:test_end].plot(ax=ax, label = \"Test\")\n",
    "predicted_test.plot(ax=ax, label = 'Predicted DT')\n",
    "arima_test.plot(ax=ax, label = 'Predicted ARIMA')\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
